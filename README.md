# Coletor de Artigos do Medium - UX + InteligÃªncia Artificial (2025)

## ğŸ“‹ DescriÃ§Ã£o

Ferramenta em Python para coleta automatizada de artigos do Medium relacionados a **UX Design** e **InteligÃªncia Artificial**, publicados no ano de **2025**.

O projeto foi desenvolvido para apoiar pesquisas de referÃªncias em UX/UI, automatizando a coleta e organizaÃ§Ã£o de conteÃºdos relevantes.

## ğŸ¯ Objetivo

- Coletar links de artigos do Medium a partir de pÃ¡ginas de _tag_
- Extrair metadados relevantes de cada artigo
- Aplicar filtro de cruzamento de tags (regra AND)
- Exportar dados finais em JSON e CSV

## ğŸ“ Estrutura do Projeto

```
article_scrapper/
â”‚
â”œâ”€â”€ main.py          # Script principal - orquestra o pipeline
â”œâ”€â”€ collector.py     # Coleta de links via Playwright
â”œâ”€â”€ parser.py        # ExtraÃ§Ã£o de metadados (JSON-LD/HTML)
â”œâ”€â”€ storage.py       # PersistÃªncia em JSON e CSV
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw_links_ux-design.json
â”‚   â”œâ”€â”€ raw_links_artificial-intelligence.json
â”‚   â”œâ”€â”€ artigos_filtrados_2025.json
â”‚   â””â”€â”€ artigos_filtrados_2025.csv
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ› ï¸ InstalaÃ§Ã£o

### 1. Criar e ativar ambiente virtual

```bash
# Windows
python -m venv .venv
.venv\Scripts\activate

# Linux/macOS
python -m venv .venv
source .venv/bin/activate
```

### 2. Instalar dependÃªncias

```bash
pip install -r requirements.txt
```

### 3. Instalar navegadores do Playwright

```bash
playwright install chromium
```

## ğŸš€ Uso

### Executar pipeline completo

```bash
python main.py
```

### Executar etapas individuais

```bash
# Apenas coleta de links
python main.py --collect

# Apenas extraÃ§Ã£o de metadados
python main.py --parse

# Apenas filtragem e exportaÃ§Ã£o
python main.py --filter
```

### Executar com navegador visÃ­vel (debug)

```bash
python main.py --headful
```

## ğŸ“Š Estrutura dos Dados

Cada artigo Ã© representado com a seguinte estrutura:

```json
{
  "titulo": "TÃ­tulo do artigo",
  "autor": "Nome do autor",
  "data_publicacao": "2025-01-15",
  "tags": ["ux-design", "artificial-intelligence", "..."],
  "tempo_leitura": "5 min read",
  "resumo": "DescriÃ§Ã£o ou resumo do artigo...",
  "fonte": "medium",
  "url": "https://medium.com/..."
}
```

## âš™ï¸ Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ETAPA 1: COLETA                         â”‚
â”‚  â€¢ Acessa pÃ¡ginas de tag do Medium                          â”‚
â”‚  â€¢ Realiza scroll para carregar conteÃºdo dinÃ¢mico           â”‚
â”‚  â€¢ Extrai URLs de artigos de 2025                           â”‚
â”‚  â€¢ Salva em: data/raw_links_<tag>.json                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 ETAPA 2: EXTRAÃ‡ÃƒO                           â”‚
â”‚  â€¢ Visita cada URL coletada                                 â”‚
â”‚  â€¢ Extrai metadados via JSON-LD (Schema.org)                â”‚
â”‚  â€¢ Fallback para HTML quando necessÃ¡rio                     â”‚
â”‚  â€¢ Salva em: data/artigos_raw_2025.json                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 ETAPA 3: FILTRAGEM                          â”‚
â”‚  â€¢ Filtra por ano de publicaÃ§Ã£o (2025)                      â”‚
â”‚  â€¢ Filtra por presenÃ§a de AMBAS as tags (AND)               â”‚
â”‚  â€¢ Exporta JSON e CSV finais                                â”‚
â”‚  â€¢ Salva em: data/artigos_filtrados_2025.{json,csv}         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ ConfiguraÃ§Ã£o

As configuraÃ§Ãµes principais estÃ£o no arquivo `main.py`:

```python
CONFIG = {
    "tags": ["ux-design", "artificial-intelligence"],
    "ano": 2025,
    "headless": True
}
```

## ğŸ“ CritÃ©rios de Filtro

Um artigo Ã© incluÃ­do no corpus final apenas se:

- âœ… Foi publicado em **2025**
- âœ… ContÃ©m **simultaneamente** as tags:
  - `ux-design`
  - `artificial-intelligence`

## âš ï¸ LimitaÃ§Ãµes

- O projeto coleta apenas **metadados**, nÃ£o o texto completo dos artigos
- Depende da estrutura atual do Medium (pode quebrar com atualizaÃ§Ãµes)
- A coleta pode demorar dependendo da quantidade de artigos
- Respeite os termos de uso do Medium

## ğŸ§ª Desenvolvimento

### Testar coleta de um artigo especÃ­fico

```python
from parser import run_parser

metadata = run_parser("https://medium.com/artigo-exemplo")
print(metadata)
```

### Testar coleta de links de uma tag

```python
from collector import run_collector

links = run_collector("ux-design", headless=False)
print(f"Coletados {len(links)} links")
```

## ğŸ“„ LicenÃ§a

Este projeto Ã© para fins educacionais e de pesquisa.

---

Desenvolvido para apoio Ã  pesquisa em UX Design ğŸ¨ + IA ğŸ¤–
